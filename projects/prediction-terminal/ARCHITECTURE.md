# Prediction Terminal - Architecture

## ğŸ—ï¸ System Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     PREDICTION TERMINAL                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Data Sources    â”‚    â”‚   Processing     â”‚    â”‚   Outputs        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                  â”‚    â”‚                  â”‚    â”‚                  â”‚
â”‚ ğŸ”´ Reddit        â”‚â”€â”€â”€â–¶â”‚ Vercel Cron Jobs â”‚â”€â”€â”€â–¶â”‚ ğŸ“Š Dashboard     â”‚
â”‚   (GummySearch)  â”‚    â”‚                  â”‚    â”‚   (Next.js)      â”‚
â”‚                  â”‚    â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚    â”‚                  â”‚
â”‚ ğŸ¦ Twitter       â”‚â”€â”€â”€â–¶â”‚ â”‚ AI Analysis  â”‚ â”‚â”€â”€â”€â–¶â”‚ ğŸ’¬ Slack Alerts  â”‚
â”‚   (Parse.bot)    â”‚    â”‚ â”‚ (GPT-4)      â”‚ â”‚    â”‚   (Webhooks)     â”‚
â”‚                  â”‚    â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚    â”‚                  â”‚
â”‚ ğŸŒ Web           â”‚â”€â”€â”€â–¶â”‚                  â”‚â”€â”€â”€â–¶â”‚ ğŸ’¾ Database      â”‚
â”‚   (Exa.ai)       â”‚    â”‚ Supabase Client  â”‚    â”‚   (PostgreSQL)   â”‚
â”‚                  â”‚    â”‚                  â”‚    â”‚                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“ Project Structure

```
prediction-terminal/
â”‚
â”œâ”€â”€ app/                          # Next.js App Router
â”‚   â”œâ”€â”€ api/                      # API routes
â”‚   â”‚   â”œâ”€â”€ cron/                # Serverless cron jobs
â”‚   â”‚   â”‚   â”œâ”€â”€ scan-reddit/     # Reddit trend scanner
â”‚   â”‚   â”‚   â”œâ”€â”€ scan-twitter/    # Twitter trend scanner
â”‚   â”‚   â”‚   â”œâ”€â”€ scan-web/        # Web trend scanner
â”‚   â”‚   â”‚   â””â”€â”€ cleanup/         # Database cleanup
â”‚   â”‚   â””â”€â”€ trends/              # Trends API
â”‚   â”œâ”€â”€ dashboard/               # Main dashboard page
â”‚   â”œâ”€â”€ layout.tsx               # Root layout
â”‚   â””â”€â”€ page.tsx                 # Home (redirects to dashboard)
â”‚
â”œâ”€â”€ components/                   # React components
â”‚   â”œâ”€â”€ trends/                  # Trend-related components
â”‚   â”‚   â”œâ”€â”€ TrendCard.tsx        # Individual trend display
â”‚   â”‚   â”œâ”€â”€ StatsBar.tsx         # System statistics
â”‚   â”‚   â””â”€â”€ FilterBar.tsx        # Filtering controls
â”‚   â””â”€â”€ ui/                      # Reusable UI components
â”‚
â”œâ”€â”€ lib/                         # Core utilities and services
â”‚   â”œâ”€â”€ supabase/               # Database client
â”‚   â”‚   â””â”€â”€ client.ts           # Supabase configuration
â”‚   â”œâ”€â”€ services/               # Business logic
â”‚   â”‚   â”œâ”€â”€ reddit.ts           # Reddit API integration
â”‚   â”‚   â”œâ”€â”€ twitter.ts          # Twitter API integration
â”‚   â”‚   â”œâ”€â”€ web.ts              # Web search integration
â”‚   â”‚   â”œâ”€â”€ openai.ts           # AI analysis service
â”‚   â”‚   â””â”€â”€ slack.ts            # Slack notifications
â”‚   â””â”€â”€ types/                  # TypeScript definitions
â”‚       â””â”€â”€ database.ts         # Database types
â”‚
â”œâ”€â”€ supabase/                    # Database schema
â”‚   â””â”€â”€ migrations/
â”‚       â””â”€â”€ 001_initial_schema.sql
â”‚
â”œâ”€â”€ scripts/                     # Utility scripts
â”‚   â””â”€â”€ setup.sh                # Automated setup
â”‚
â”œâ”€â”€ .env.example                 # Environment template
â”œâ”€â”€ vercel.json                  # Vercel cron config
â”œâ”€â”€ README.md                    # Project overview
â”œâ”€â”€ SETUP.md                     # Setup instructions
â””â”€â”€ ARCHITECTURE.md              # This file
```

## ğŸ”„ Data Flow

### 1. Trend Detection

```
External API â†’ Cron Job â†’ Database (trends table)
```

**Process:**
1. Vercel cron triggers at scheduled intervals
2. Fetches trending content from data sources
3. Checks for duplicates using `(source, source_id)` unique constraint
4. Inserts new trends with status `analyzing`

### 2. AI Analysis

```
Trend â†’ OpenAI GPT-4 â†’ Analysis (stored in analyses table)
```

**Process:**
1. For each new trend, extract key information
2. Send to GPT-4 with specialized prompt
3. Receive structured analysis:
   - Market potential (high/medium/low/none)
   - Confidence score (0-1)
   - Summary and reasoning
   - Suggested market structures
   - Keywords
4. Store analysis linked to trend

### 3. Alert Distribution

```
High/Medium Potential â†’ Slack Webhook â†’ Team Notification
```

**Process:**
1. Check if trend has high or medium potential
2. Format rich Slack message with blocks
3. Send to configured webhook
4. Record alert in alerts table
5. Update trend status to `alerted`

### 4. Dashboard Display

```
Database View â†’ Real-time Subscription â†’ Dashboard Update
```

**Process:**
1. Dashboard queries `high_potential_trends` view
2. Supabase real-time subscription detects changes
3. Dashboard automatically refreshes
4. Users can filter by potential and source

## ğŸ—„ï¸ Database Schema

### Core Tables

**trends**
- Stores detected trends from all sources
- Unique constraint on (source, source_id)
- Tracks engagement and status

**analyses**
- AI-generated insights for each trend
- Links to trends via foreign key
- Contains market potential assessment

**alerts**
- Records sent Slack notifications
- Links to both trends and analyses
- Tracks Slack message timestamps

**source_metadata**
- Monitors API health and usage
- One row per data source
- Tracks scan status and frequency

### Enums

- `source_type`: reddit, twitter, web
- `trend_status`: pending, analyzing, analyzed, alerted, dismissed
- `market_potential`: high, medium, low, none

### Indexes

Optimized for:
- Status-based queries
- Time-range queries
- Source filtering
- Engagement sorting

## âš™ï¸ Key Technologies

### Frontend
- **Next.js 14**: React framework with App Router
- **TypeScript**: Type-safe development
- **Tailwind CSS**: Utility-first styling
- **Supabase Client**: Real-time database subscriptions

### Backend
- **Vercel Serverless**: Cron jobs and API routes
- **Supabase**: PostgreSQL database with real-time
- **OpenAI GPT-4**: Trend analysis
- **External APIs**: Data aggregation

### Infrastructure
- **Vercel**: Hosting and cron jobs
- **Supabase**: Database hosting
- **Slack**: Notification delivery

## ğŸ” Security Considerations

### API Keys
- All sensitive keys in environment variables
- Service role key only used server-side
- Cron endpoints protected with bearer token

### Database
- Row-level security can be added
- Service role bypasses RLS for cron jobs
- Public anon key for dashboard (read-only views)

### Rate Limiting
- Cron jobs process limited batches
- Delays between API calls
- Metadata tracks daily API usage

## ğŸš€ Deployment

### Development
```bash
npm run dev
```
- Local Next.js server on :3000
- Hot reload enabled
- Can test cron endpoints manually

### Production
```bash
vercel --prod
```
- Deploys to Vercel edge network
- Environment variables from dashboard
- Cron jobs automatically configured

## ğŸ“Š Monitoring & Observability

### Metrics to Track
- **Trends per hour**: Detection rate
- **High potential ratio**: Quality of detection
- **API usage**: Cost tracking
- **Cron job duration**: Performance
- **Error rates**: System health

### Logging
- Vercel function logs
- Supabase query logs
- Slack system notifications

### Alerts
- Cron job failures â†’ Slack
- High-potential trends â†’ Slack
- Database errors â†’ Console logs

## ğŸ”§ Customization Points

### Add New Data Sources
1. Create service in `lib/services/`
2. Add cron job in `app/api/cron/`
3. Update `source_type` enum
4. Add source to `source_metadata`

### Modify AI Analysis
- Edit prompt in `lib/services/openai.ts`
- Adjust confidence thresholds
- Add custom evaluation criteria

### Customize Dashboard
- Modify components in `components/`
- Add new filters or views
- Change color scheme in Tailwind config

### Extend Database
- Add migration in `supabase/migrations/`
- Update types in `lib/types/database.ts`
- Modify queries as needed

## ğŸ“ˆ Scaling Considerations

### Current Limits
- **Cron frequency**: 4 jobs (15min, 30min, 1h, 6h)
- **Batch size**: ~20-50 trends per scan
- **Timeout**: 60 seconds per function
- **Database**: Supabase free tier

### To Scale Up
1. **Increase cron frequency**: Edit `vercel.json`
2. **Parallel processing**: Add more workers
3. **Database optimization**: Add indexes, partitioning
4. **Caching**: Add Redis for frequently accessed data
5. **Queue system**: Replace cron with message queue
6. **Load balancing**: Multiple Vercel regions

## ğŸ¯ Performance Optimization

### Current Optimizations
- Database indexes on common queries
- Batch processing in cron jobs
- Efficient Supabase queries
- Real-time subscriptions (not polling)

### Future Improvements
- Implement caching layer
- Optimize AI prompt length
- Parallel API calls where possible
- Pre-compute dashboard metrics
- Use Vercel Edge Functions for lower latency

## ğŸ§ª Testing Strategy

### Unit Tests
- Service functions (reddit, twitter, web, openai, slack)
- Type validation
- Utility functions

### Integration Tests
- API endpoints
- Database operations
- End-to-end trend processing

### Manual Testing
- Cron job execution
- Dashboard real-time updates
- Slack notification formatting
- Filter and search functionality

---

Built with â¤ï¸ for the Polymarket team
